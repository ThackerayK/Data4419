{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba4c27c8-d79f-4176-99df-c6226bbfed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Merged and Cleaned DataFrame Head:\n",
      "   order_id  product_id  reordered           product_name  aisle_id  \\\n",
      "0         2       33120          1     Organic Egg Whites        86   \n",
      "1         2       28985          1  Michigan Organic Kale        83   \n",
      "2         2        9327          0          Garlic Powder       104   \n",
      "3         2       45918          1         Coconut Butter        19   \n",
      "4         2       30035          0      Natural Sweetener        17   \n",
      "\n",
      "   department_id               aisle  department  user_id eval_set  \\\n",
      "0             16                eggs  dairy eggs   202279    prior   \n",
      "1              4    fresh vegetables     produce   202279    prior   \n",
      "2             13   spices seasonings      pantry   202279    prior   \n",
      "3             13       oils vinegars      pantry   202279    prior   \n",
      "4             13  baking ingredients      pantry   202279    prior   \n",
      "\n",
      "   order_number  order_dow  order_hour_of_day  days_since_prior_order  \n",
      "0             3          5                  9                     8.0  \n",
      "1             3          5                  9                     8.0  \n",
      "2             3          5                  9                     8.0  \n",
      "3             3          5                  9                     8.0  \n",
      "4             3          5                  9                     8.0  \n",
      "\n",
      "Final DataFrame Shape: (33819106, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "orders = pd.read_csv(\"C:/Users/kthac/Desktop/Group_4419/archive (3)/orders.csv\")\n",
    "order_products_prior = pd.read_csv(\"C:/Users/kthac/Desktop/Group_4419/archive (3)/order_products__prior.csv\")\n",
    "order_products_train = pd.read_csv(\"C:/Users/kthac/Desktop/Group_4419/archive (3)/order_products__train.csv\")\n",
    "products = pd.read_csv(\"C:/Users/kthac/Desktop/Group_4419/archive (3)/products.csv\")\n",
    "aisles = pd.read_csv(\"C:/Users/kthac/Desktop/Group_4419/archive (3)/aisles.csv\")\n",
    "departments = pd.read_csv(\"C:/Users/kthac/Desktop/Group_4419/archive (3)/departments.csv\")\n",
    "\n",
    "\n",
    "# --- Step 1: Merge Orders and Order Products ---\n",
    "# The 'prior' and 'train' datasets need to be combined as they both contain product-level order information.\n",
    "# The 'eval_set' column in the orders dataframe indicates whether the order is 'prior', 'train', or 'test'[cite: 34].\n",
    "\n",
    "# Combine prior and train order products datasets\n",
    "order_products = pd.concat([order_products_prior, order_products_train], ignore_index=True)\n",
    "\n",
    "# --- Step 2: Merge Product Metadata ---\n",
    "# Join the product details (name, aisle, department) with the order products data.\n",
    "\n",
    "# Merge products with aisles and departments to get their names\n",
    "products_metadata = pd.merge(products, aisles, on='aisle_id', how='left')\n",
    "products_metadata = pd.merge(products_metadata, departments, on='department_id', how='left')\n",
    "\n",
    "# Merge the combined order products data with the products metadata\n",
    "# This step enriches each product in an order with its descriptive information.\n",
    "df_merged = pd.merge(order_products, products_metadata, on='product_id', how='left')\n",
    "\n",
    "# --- Step 3: Merge with Order Metadata ---\n",
    "# Join the order details (user_id, order_number, etc.) with the merged dataframe.\n",
    "# The 'orders' dataframe contains metadata for all customer orders, including the user and the order number[cite: 31, 35].\n",
    "\n",
    "# The 'orders' dataframe contains about 3.4 million rows[cite: 37]. The 'order_products_prior' dataframe\n",
    "# contains about 32.4 million rows[cite: 42].\n",
    "# This is a large merge, so it may take some time.\n",
    "df_merged = pd.merge(df_merged, orders, on='order_id', how='left')\n",
    "\n",
    "# --- Final Cleanup and Preparation ---\n",
    "# The final dataframe, 'merged_df', now contains a comprehensive view of all product purchases.\n",
    "# It's a large and heterogeneous dataset, well-suited for the project's algorithms[cite: 62, 64].\n",
    "\n",
    "# Optional: Drop redundant columns if not needed for your specific analysis\n",
    "df_merged = df_merged.drop(columns=['add_to_cart_order'])\n",
    "\n",
    "# Display the first few rows of the final cleaned dataframe to confirm the merge was successful\n",
    "print(\"\\nFinal Merged and Cleaned DataFrame Head:\")\n",
    "print(df_merged.head())\n",
    "\n",
    "# Display the shape of the final dataframe\n",
    "print(f\"\\nFinal DataFrame Shape: {df_merged.shape}\")\n",
    "\n",
    "# Now, this 'merged_df' can be used as the basis for Phase 2 of the project,\n",
    "# where you will build the Item-Item Collaborative Filtering model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
